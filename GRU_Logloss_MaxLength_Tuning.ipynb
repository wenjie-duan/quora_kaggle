{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup-&amp;-Summary\" data-toc-modified-id=\"Setup-&amp;-Summary-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup &amp; Summary</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-my-kaggle-API\" data-toc-modified-id=\"Setup-my-kaggle-API-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup my kaggle API</a></span></li><li><span><a href=\"#Download-data-from-Kaggle\" data-toc-modified-id=\"Download-data-from-Kaggle-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Download data from Kaggle</a></span></li></ul></li><li><span><a href=\"#Load-&amp;-Explore-Data\" data-toc-modified-id=\"Load-&amp;-Explore-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load &amp; Explore Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Explore-data\" data-toc-modified-id=\"Explore-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Explore data</a></span></li></ul></li><li><span><a href=\"#Benchmark-Model\" data-toc-modified-id=\"Benchmark-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Benchmark Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Submit-to-Kaggle\" data-toc-modified-id=\"Submit-to-Kaggle-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Submit to Kaggle</a></span></li></ul></li><li><span><a href=\"#Process-Data\" data-toc-modified-id=\"Process-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Process Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clean-dataset\" data-toc-modified-id=\"Clean-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Clean dataset</a></span></li><li><span><a href=\"#Split-train-and-validation\" data-toc-modified-id=\"Split-train-and-validation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Split train and validation</a></span></li><li><span><a href=\"#Upsample-minority-for-imbalanced-dataset\" data-toc-modified-id=\"Upsample-minority-for-imbalanced-dataset-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Upsample minority for imbalanced dataset</a></span></li><li><span><a href=\"#Get-vocab2index,-and-prepare-initialize-embedding-with-a-pre-trained-Glove\" data-toc-modified-id=\"Get-vocab2index,-and-prepare-initialize-embedding-with-a-pre-trained-Glove-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Get vocab2index, and prepare initialize embedding with a pre-trained Glove</a></span></li></ul></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Encode-data\" data-toc-modified-id=\"Encode-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Encode data</a></span></li><li><span><a href=\"#Dynamic-padding-+-pack_padded_sequence\" data-toc-modified-id=\"Dynamic-padding-+-pack_padded_sequence-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Dynamic padding + pack_padded_sequence</a></span></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implement-model\" data-toc-modified-id=\"Implement-model-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Implement model</a></span></li><li><span><a href=\"#Debug-model\" data-toc-modified-id=\"Debug-model-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Debug model</a></span></li></ul></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-functions\" data-toc-modified-id=\"Training-functions-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Training functions</a></span></li><li><span><a href=\"#Explore-learning--rate-with-subsample\" data-toc-modified-id=\"Explore-learning--rate-with-subsample-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Explore learning  rate with subsample</a></span></li><li><span><a href=\"#Finally-training-epochs\" data-toc-modified-id=\"Finally-training-epochs-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Finally training epochs</a></span></li></ul></li><li><span><a href=\"#Predict-and-submit\" data-toc-modified-id=\"Predict-and-submit-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Predict and submit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predict-y_test\" data-toc-modified-id=\"Predict-y_test-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Predict y_test</a></span></li><li><span><a href=\"#Submit-to-Kaggle\" data-toc-modified-id=\"Submit-to-Kaggle-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Submit to Kaggle</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup my kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYsD9XxjbEqJ"
   },
   "source": [
    "## Download data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fofJReyNbcP_"
   },
   "source": [
    "\n",
    "Unzip the training and test datasets into data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c Quora-Question-Pairs -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unzip datasets to data directory\n",
    "# !unzip data/Quora-Question-Pairs.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unzip training and test datasets to data directory\n",
    "# !unzip data/test.csv.zip -d data\n",
    "# !unzip data/train.csv.zip -d data\n",
    "# !unzip data/sample_submission.csv.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t  sample_submission.csv.zip  train.csv\r\n",
      "Quora-Question-Pairs.zip  test.csv\t\t     train.csv.zip\r\n",
      "sample_submission.csv\t  test.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBvwpiLXbmGn"
   },
   "source": [
    "# Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N274iDTYbtJG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FWFWzG0TmfL"
   },
   "outputs": [],
   "source": [
    "data_dir = Path('./data')\n",
    "df_train = pd.read_csv(data_dir / 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1178
    },
    "colab_type": "code",
    "id": "rBZTyLcX4XgI",
    "outputId": "7b578c8e-a94c-424f-a4ba-7c2605704dbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View train data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>217243.942418</td>\n",
       "      <td>220955.655337</td>\n",
       "      <td>0.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.614502</td>\n",
       "      <td>157751.700002</td>\n",
       "      <td>159903.182629</td>\n",
       "      <td>0.482588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101072.250000</td>\n",
       "      <td>74437.500000</td>\n",
       "      <td>74727.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>192182.000000</td>\n",
       "      <td>197052.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303216.750000</td>\n",
       "      <td>346573.500000</td>\n",
       "      <td>354692.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>537932.000000</td>\n",
       "      <td>537933.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1           qid2   is_duplicate\n",
       "count  404290.000000  404290.000000  404290.000000  404290.000000\n",
       "mean   202144.500000  217243.942418  220955.655337       0.369198\n",
       "std    116708.614502  157751.700002  159903.182629       0.482588\n",
       "min         0.000000       1.000000       2.000000       0.000000\n",
       "25%    101072.250000   74437.500000   74727.000000       0.000000\n",
       "50%    202144.500000  192182.000000  197052.000000       0.000000\n",
       "75%    303216.750000  346573.500000  354692.500000       1.000000\n",
       "max    404289.000000  537932.000000  537933.000000       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe() #imbalanced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537933"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_train = set(df_train.qid1.unique()).union(set(df_train.qid2.unique()))\n",
    "len(qid_train) # total questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133643"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qid_train)-df_train.shape[0] # duplicated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(data_dir / 'test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.369197853026293"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = df_train.is_duplicate.mean()\n",
    "p \n",
    "# always set the this value as prediction, get logloss score = 0.55 in leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': p})\n",
    "# sub.to_csv('naive_submission.csv', index=False)\n",
    "# !kaggle competitions submit -c Quora-Question-Pairs -f naive_submission.csv -m \"naive_submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\" Read file returns a shuttled list.\n",
    "    \"\"\"\n",
    "    with open(path, encoding = \"ISO-8859-1\") as f:\n",
    "        content = np.array(f.readlines())\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(list_of_content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for content in list_of_content:\n",
    "        for left, right in content: #left and right in one content\n",
    "            left = left.strip()\n",
    "            right = right.strip()\n",
    "            words_left = set(left.split())\n",
    "            words_right = set(right.split())\n",
    "            for word in words_left:\n",
    "                vocab[word] += 1\n",
    "            for word in words_right:\n",
    "                vocab[word] += 1\n",
    "    return vocab       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['question1']=df_train['question1'].apply(lambda  x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['question2']=df_train['question2'].apply(lambda  x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val[['question1','question2']].values\n",
    "y_val = val.is_duplicate.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample minority for imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369197853026293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train.is_duplicate.values\n",
    "print(sum(y)/len(y))# imbalanced dataset, y=1 is the minority\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = df_train[df_train.is_duplicate==0]\n",
    "minority = df_train[df_train.is_duplicate==1]\n",
    "# upsample minority\n",
    "minority_upsampled = resample(minority,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(majority), # match number in majority class\n",
    "                          random_state=42) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([majority, minority_upsampled])\n",
    "sum(upsampled.is_duplicate)/len(upsampled.is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = upsampled[['question1','question2']].values\n",
    "y_train = upsampled.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['what is the step by step guide to invest in share market in india \\\\?',\n",
       "        'what is the step by step guide to invest in share market \\\\?'],\n",
       "       ['what is the story of kohinoor \\\\( koh i noor \\\\) diamond \\\\?',\n",
       "        'what would happen if the indian government stole the kohinoor \\\\( koh i noor \\\\) diamond back \\\\?'],\n",
       "       ['how can i increase the speed of my internet connection while using a vpn \\\\?',\n",
       "        'how can internet speed be increased by hacking through dns \\\\?'],\n",
       "       ['why am i mentally very lonely \\\\? how can i solve it \\\\?',\n",
       "        'find the remainder when math 23 24 math is divided by 24 , 23 \\\\?'],\n",
       "       ['which one dissolve in water quikly sugar , salt , methane and carbon di oxide \\\\?',\n",
       "        'which fish would survive in salt water \\\\?']], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab2index, and prepare initialize embedding with a pre-trained Glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile=Path('../lab-4-gru-wenjie-duan/data/glove.6B.50d.txt')):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let compute the vocab again\n",
    "word_count = get_vocab([X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 87868\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vecs.keys()), len(word_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rare_words(word_vecs, word_count, min_df=4):\n",
    "    \"\"\" Deletes rare words from word_count\n",
    "    \n",
    "    Deletes words from word_count if they are not in word_vecs\n",
    "    and don't have at least min_df occurrencies in word_count.\n",
    "    \"\"\"\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63809\n"
     ]
    }
   ],
   "source": [
    "word_count = delete_rare_words(word_vecs, word_count)\n",
    "print(len(word_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    V = len(word_count.keys()) + 2\n",
    "    vocab2index = {}\n",
    "    W = np.zeros((V, emb_size), dtype=\"float32\")\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    vocab2index[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1   \n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weight, vocab, vocab2index = create_embedding_matrix(word_vecs, word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63811"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pretrained_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1662, -0.0191, -0.0600,  ..., -0.1047, -0.2422,  0.0405],\n",
       "        [ 0.4532,  0.0598, -0.1058,  ...,  0.5324, -0.2510,  0.6255],\n",
       "        ...,\n",
       "        [-0.1498, -0.0614, -1.3842,  ...,  0.7347, -1.1656, -1.0799],\n",
       "        [ 0.5151,  0.0278, -0.4212,  ..., -0.5878,  0.6414, -2.0988],\n",
       "        [-0.1180, -0.2042, -0.4037,  ..., -0.2884,  0.9183, -0.4045]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an embedding matrix with Glove embeddings\n",
    "emb_size = 50\n",
    "V = len(pretrained_weight)\n",
    "emb = nn.Embedding(V, emb_size)\n",
    "emb.weight.data.copy_(torch.from_numpy(pretrained_weight)) # copy  from Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1662, -0.0191, -0.0600,  ..., -0.1047, -0.2422,  0.0405],\n",
       "        [ 0.4532,  0.0598, -0.1058,  ...,  0.5324, -0.2510,  0.6255],\n",
       "        ...,\n",
       "        [-0.1498, -0.0614, -1.3842,  ...,  0.7347, -1.1656, -1.0799],\n",
       "        [ 0.5151,  0.0278, -0.4212,  ..., -0.5878,  0.6414, -2.0988],\n",
       "        [-0.1180, -0.2042, -0.4037,  ..., -0.2884,  0.9183, -0.4045]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight  # emb is pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9400,  0.8914,  0.7156,  ...,  1.1492, -1.6578,  0.1789],\n",
       "        [-0.0321,  0.2208, -1.4044,  ...,  1.4767, -0.8019,  1.4304],\n",
       "        [ 1.5595,  0.2448, -0.2031,  ...,  0.1336, -0.8925,  0.1267],\n",
       "        ...,\n",
       "        [ 0.9069, -0.3408,  1.0463,  ...,  1.6598,  0.3246,  1.3094],\n",
       "        [ 0.0618, -0.1023, -0.0845,  ...,  2.7552,  0.3336,  0.1429],\n",
       "        [-2.4804, -2.0402, -0.0655,  ...,  0.6481,  1.9671, -0.1751]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(V, emb_size).weight # an example of random embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'UNK', 'what', 'is', 'step', 'to', 'in', 'the', 'india',\n",
       "       'invest'], dtype='<U52')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_no_padding(line, vocab2index):\n",
    "    words = line.split()\n",
    "    return np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, X, y,train=True):\n",
    "        self.train = train\n",
    "        self.x  = X\n",
    "        self.y = y\n",
    "        self.x = [(encode_sentence_no_padding(left, vocab2index)\n",
    "                   ,encode_sentence_no_padding(right, vocab2index)) for left, right in self.x]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return self.x[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.x[idx]\n",
    "\n",
    "train_ds = QuoraDataset(X_train, y_train)\n",
    "valid_ds = QuoraDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what is the step by step guide to invest in share market in india \\\\?',\n",
       "       'what is the step by step guide to invest in share market \\\\?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  3,  7,  4, 13,  4, 14,  5,  9,  6, 11, 10,  6,  8, 12]),\n",
       " array([ 2,  3,  7,  4, 13,  4, 14,  5,  9,  6, 11, 10, 12]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic padding + pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding\n",
    "    ).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (sentence, label). \n",
    "            - list of word indices of variable length\n",
    "            - label, 0 or 1\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: max(len(x[0][0]),len(x[0][1])), reverse=True) # the max of left and right sentence length\n",
    "    sentences, labels = zip(*data)\n",
    "    \n",
    "    # stack labels\n",
    "    labels = torch.Tensor(labels)\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [max(len(left), len(right)) for left, right in sentences]\n",
    "   \n",
    "    sents_left = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    sents_right = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    \n",
    "    for i, s in enumerate(sentences):\n",
    "        end = len(s[0])\n",
    "        sents_left[i, :end] = torch.Tensor(s[0][:end])        \n",
    "    \n",
    "    for i, s in enumerate(sentences):\n",
    "        end = len(s[1])\n",
    "        sents_right[i, :end] = torch.Tensor(s[1][:end])   \n",
    "    \n",
    "    return sents_left, sents_right, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_left, sents_right, lengths, labels = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   49,     8,   235,   150,  5319,  5913, 15710,   127,  7762,    60,\n",
       "            51,   350,  2969,   127,     8,    12,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [    2,     3,     7,   701,    23,     7,  1487,  1062,     1,    12,\n",
       "            49,     3,   276,  1062,  8778,  1303,   927,     6,  4929,    12,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [    2,     3,     7,   135,   198,    23,  1456,  3235,   690,    12,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  349,  5963,     7,    40,    12,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [   34,    32,    19, 30835,  3259,   148,   574,  1535,    39,  7816,\n",
       "            12,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  203,     7,  2753,   169,   234,     3,   425,   198,     6,     7,\n",
       "           700,     5, 31346,     7,  3095,    18,  1927,     1, 14743,    21,\n",
       "         31347,    13,     8,    61,    49,   171,     8,   215,  9513,   467,\n",
       "             6,   106,   207,  1689,    12],\n",
       "        [ 1487,  6464,    62,   225,     2,  1182,   171,     7,  1062, 47819,\n",
       "           172,    12,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [    2,     3,     7,   135,   198,     5,   383,    38,  1456,    13,\n",
       "          1279,    12,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  349,  5963,     7,    40,    12,    34,   262,   276,  4510,     7,\n",
       "           636,    12,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [   34,    88,    19,  3669, 30835,  7351,     6,  7816,    12,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 35]), torch.Size([5]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_left.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 20, 12, 12, 11]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights=None) :\n",
    "        super(GRUModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # use pre_trained embed\n",
    "        if glove_weights is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "            self.embedding.weight.requires_grad = False ## freeze embeddings\n",
    "\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        #self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x1, x2,lengths):\n",
    "        x1 = self.embedding(x1)\n",
    "        x2 = self.embedding(x2)\n",
    "        x1 = self.dropout(x1)\n",
    "        x2 = self.dropout(x2)\n",
    "        pack1 = pack_padded_sequence(x1, lengths, batch_first=True)\n",
    "        pack2 = pack_padded_sequence(x2, lengths, batch_first=True)\n",
    "        out_pack1, ht1 = self.gru(pack1)\n",
    "        out_pack2, ht2 = self.gru(pack2)\n",
    "        #distance = torch.exp(-abs(self.linear(ht1[-1])-self.linear(ht2[-1])))\n",
    "        distance = torch.exp(-torch.sum(torch.abs(ht1[-1]-ht2[-1]),dim=1))\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50 \n",
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(pretrained_weight)\n",
    "emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "gru=nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "linear = nn.Linear(hidden_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = DataLoader(train_ds, batch_size=3, shuffle=True, collate_fn=collate_fn)\n",
    "x_left, x_right, s, y = next(iter(tr_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_left = x_left.long()\n",
    "x_right = x_right.long()\n",
    "y = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1571],\n",
       "        [-0.1422],\n",
       "        [-0.0258]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_left = emb(x_left)\n",
    "pack = pack_padded_sequence(x_left, s, batch_first=True)\n",
    "out_pack, ht = gru(pack)\n",
    "y_pred_left = linear(ht[-1])\n",
    "y_pred_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1359],\n",
       "        [-0.1034],\n",
       "        [-0.0757]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_right = emb(x_right)\n",
    "pack = pack_padded_sequence(x_right, s, batch_first=True)\n",
    "out_pack, ht = gru(pack)\n",
    "y_pred_right = linear(ht[-1])\n",
    "y_pred_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9790],\n",
       "        [0.9619],\n",
       "        [0.9513]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import e\n",
    "distance = e**(-abs(y_pred_left - y_pred_right))\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0276340246200562"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.binary_cross_entropy(distance, y.unsqueeze(1))\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (distance>threshold)\n",
    "y_pred.reshape(-1)==y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "    \n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr\n",
    "        \n",
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations, div_start=5, div_end=5):\n",
    "    min_start, min_end = max_lr/div_start, max_lr/div_end\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)\n",
    "\n",
    "N = 100000\n",
    "lr = get_cosine_triangular_lr(0.01, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, optimizer, train_dl, valid_dl, max_lr=0.1, epochs=10):\n",
    "    \n",
    "    iterations = epochs*len(train_dl) # epochs*number of batches \n",
    "    pbar = tqdm(total=iterations)# timeline  \n",
    "    \n",
    "    idx = 0\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations) \n",
    "    \n",
    "    highest_loss = float('inf')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for x_left, x_right, s, y in train_dl:\n",
    "            \n",
    "            update_optimizer(optimizer, lrs[idx])\n",
    "            \n",
    "            x_left = x_left.long().cuda()\n",
    "            x_right = x_right.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            \n",
    "            # distance \n",
    "            distance = model(x_left, x_right, s)  # the  distance would between  0-1 \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy(distance, y.unsqueeze(1)) # deleted _with_logits\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "            pbar.update()\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train loss %.4f val loss %.4f and val accuracy %.4f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        \n",
    "        if val_loss < highest_loss:\n",
    "            highest_loss = val_loss\n",
    "            path = \"./models/{0}_{1}_loss_{2:.0f}.pth\".format('gru_subset',max_lr,1000*val_loss) \n",
    "            save_model(model, path)\n",
    "\n",
    "            print(path)\n",
    "        \n",
    "        \n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x_left, x_right, s, y in train_dl:\n",
    "        \n",
    "        x_left = x_left.long().cuda()\n",
    "        x_right = x_right.long().cuda()\n",
    "        y = y.float().cuda()\n",
    "        \n",
    "        # distance \n",
    "        distance = model(x_left,x_right,s) # the  distance would between  0-1\n",
    "        # malstm_distance is y \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.binary_cross_entropy(distance, y.unsqueeze(1)) # deleted _with_logits\n",
    "        \n",
    "        y_pred = (distance > threshold) # between 0~1\n",
    "        y_pred= y_pred.view(-1)\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore learning  rate with subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.027"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "inds=np.random.choice(range(X_train.shape[0]),256)\n",
    "X_train_subsample =  X_train[inds,:]\n",
    "y_train_subsample = y_train[inds]\n",
    "train_ds_subsample = QuoraDataset(X_train_subsample, y_train_subsample)\n",
    "inds_val=np.random.choice(range(X_val.shape[0]),64)\n",
    "X_val_subsample =  X_val[inds_val,:]\n",
    "y_val_subsample = y_val[inds_val]\n",
    "valid_ds_subsample = QuoraDataset(X_val_subsample, y_val_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl_subsample = DataLoader(train_ds_subsample, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl_subsample = DataLoader(valid_ds_subsample, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1283769b0d4341bc18c17010d1c6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 17.9624 val loss 25.3698 and val accuracy 0.5007\n",
      "./models/gru_subset_1_loss_25370.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf40d3a8a174a0987fd7929738b1a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 29.4553 val loss 28.9936 and val accuracy 0.5006\n",
      "./models/gru_subset_1_loss_28994.pth\n",
      "train loss 32.3208 val loss 30.5646 and val accuracy 0.5006\n",
      "train loss 33.4246 val loss 31.3407 and val accuracy 0.5006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2eb241caff4e35876cf6ddbcfaa597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 3.8248 val loss 1.6592 and val accuracy 0.5156\n",
      "./models/gru_subset_0.1_loss_1659.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb9d16ded6e45d7ae02e112b1974588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.5126 val loss 1.2013 and val accuracy 0.5216\n",
      "./models/gru_subset_0.1_loss_1201.pth\n",
      "train loss 1.8815 val loss 0.9813 and val accuracy 0.5280\n",
      "./models/gru_subset_0.1_loss_981.pth\n",
      "train loss 1.5162 val loss 0.8431 and val accuracy 0.5323\n",
      "./models/gru_subset_0.1_loss_843.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fa42a6610c4a7086cd85abb859575c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.6172 val loss 2.5068 and val accuracy 0.5118\n",
      "./models/gru_subset_0.01_loss_2507.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529792addadd424d84ec783b7acca9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 3.7411 val loss 2.0294 and val accuracy 0.5135\n",
      "./models/gru_subset_0.01_loss_2029.pth\n",
      "train loss 3.3122 val loss 1.7587 and val accuracy 0.5150\n",
      "./models/gru_subset_0.01_loss_1759.pth\n",
      "train loss 2.9516 val loss 1.5718 and val accuracy 0.5170\n",
      "./models/gru_subset_0.01_loss_1572.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a507ab1c4107483591d79ecff1fd7603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.2369 val loss 3.6159 and val accuracy 0.5107\n",
      "./models/gru_subset_0.001_loss_3616.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a56c06fafe84ef29c541c4bc5ea0890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.8429 val loss 3.4553 and val accuracy 0.5109\n",
      "./models/gru_subset_0.001_loss_3455.pth\n",
      "train loss 5.0440 val loss 3.3040 and val accuracy 0.5112\n",
      "./models/gru_subset_0.001_loss_3304.pth\n",
      "train loss 4.6843 val loss 3.1684 and val accuracy 0.5114\n",
      "./models/gru_subset_0.001_loss_3168.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b273aca89d145278c40303ef3094efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.8816 val loss 3.3934 and val accuracy 0.5107\n",
      "./models/gru_subset_0.0001_loss_3393.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea611a9174c4532bfbdf6d30cf6504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.9922 val loss 3.3780 and val accuracy 0.5108\n",
      "./models/gru_subset_0.0001_loss_3378.pth\n",
      "train loss 4.8421 val loss 3.3628 and val accuracy 0.5108\n",
      "./models/gru_subset_0.0001_loss_3363.pth\n",
      "train loss 4.9660 val loss 3.3475 and val accuracy 0.5108\n",
      "./models/gru_subset_0.0001_loss_3348.pth\n"
     ]
    }
   ],
   "source": [
    "for try_lr in [1,0.1,0.01,0.001,0.0001]:\n",
    "    model = GRUModel(len(pretrained_weight), emb_size, 100, glove_weights=pretrained_weight).cuda() \n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.1, weight_decay=1e-5)\n",
    "    train_epochs(model, optimizer, train_dl_subsample, valid_dl_subsample, max_lr=try_lr, epochs=1)\n",
    "    # unfreezing the embeddings\n",
    "    model.embedding.weight.requires_grad = True\n",
    "    train_epochs(model, optimizer, train_dl_subsample, valid_dl_subsample, max_lr=try_lr, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(len(pretrained_weight), emb_size, 100, glove_weights=pretrained_weight).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2534da55b1415da2c73b6affb2b9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.9704 val loss 0.7193 and val accuracy 0.5824\n",
      "./models/gru_subset_0.1_loss_719.pth\n",
      "train loss 0.6653 val loss 0.6830 and val accuracy 0.6414\n",
      "./models/gru_subset_0.1_loss_683.pth\n"
     ]
    }
   ],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.1, weight_decay=1e-5)\n",
    "train_epochs(model, optimizer, train_dl, valid_dl, max_lr=0.1, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreezing the embeddings\n",
    "model.embedding.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccdcb7c90b0478e88909ed201832593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6577 val loss 0.7157 and val accuracy 0.5921\n",
      "./models/gru_subset_0.1_loss_716.pth\n",
      "train loss 0.6542 val loss 0.7044 and val accuracy 0.6310\n",
      "./models/gru_subset_0.1_loss_704.pth\n",
      "train loss 0.6408 val loss 0.7858 and val accuracy 0.5680\n",
      "train loss 0.6323 val loss 0.6735 and val accuracy 0.6552\n",
      "./models/gru_subset_0.1_loss_673.pth\n",
      "train loss 0.6228 val loss 0.7019 and val accuracy 0.6352\n",
      "train loss 0.6169 val loss 0.6457 and val accuracy 0.6769\n",
      "./models/gru_subset_0.1_loss_646.pth\n",
      "train loss 0.6116 val loss 0.6669 and val accuracy 0.6658\n",
      "train loss 0.6086 val loss 0.6402 and val accuracy 0.6824\n",
      "./models/gru_subset_0.1_loss_640.pth\n",
      "train loss 0.6109 val loss 0.6269 and val accuracy 0.6941\n",
      "./models/gru_subset_0.1_loss_627.pth\n",
      "train loss 0.6098 val loss 0.6648 and val accuracy 0.6680\n",
      "train loss 0.6045 val loss 0.6729 and val accuracy 0.6565\n",
      "train loss 0.6030 val loss 0.6350 and val accuracy 0.6868\n",
      "train loss 0.6026 val loss 0.7124 and val accuracy 0.6322\n",
      "train loss 0.6014 val loss 0.6253 and val accuracy 0.6949\n",
      "./models/gru_subset_0.1_loss_625.pth\n",
      "train loss 0.6027 val loss 0.6556 and val accuracy 0.6758\n",
      "train loss 0.6003 val loss 0.6715 and val accuracy 0.6621\n",
      "train loss 0.5974 val loss 0.7031 and val accuracy 0.6395\n",
      "train loss 0.5998 val loss 0.6509 and val accuracy 0.6792\n",
      "train loss 0.5980 val loss 0.6608 and val accuracy 0.6684\n",
      "train loss 0.5961 val loss 0.7220 and val accuracy 0.6265\n",
      "train loss 0.5975 val loss 0.7971 and val accuracy 0.5787\n",
      "train loss 0.6012 val loss 0.6379 and val accuracy 0.6857\n",
      "train loss 0.5984 val loss 0.6578 and val accuracy 0.6705\n",
      "train loss 0.5950 val loss 0.6250 and val accuracy 0.6960\n",
      "./models/gru_subset_0.1_loss_625.pth\n",
      "train loss 0.5969 val loss 0.6710 and val accuracy 0.6616\n",
      "train loss 0.5942 val loss 0.6356 and val accuracy 0.6863\n",
      "train loss 0.5937 val loss 0.6826 and val accuracy 0.6549\n",
      "train loss 0.5921 val loss 0.6406 and val accuracy 0.6842\n",
      "train loss 0.5943 val loss 0.6697 and val accuracy 0.6593\n",
      "train loss 0.5907 val loss 0.7280 and val accuracy 0.6127\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, optimizer, train_dl, valid_dl, max_lr=0.1, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model,'./models/gru_subset_0.1_loss_625.pth')\n",
    "model.embedding.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297f520950e49ea8764e64bdbf34f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.5903 val loss 0.6700 and val accuracy 0.6619\n",
      "./models/gru_subset_0.01_loss_670.pth\n",
      "train loss 0.5876 val loss 0.6604 and val accuracy 0.6685\n",
      "./models/gru_subset_0.01_loss_660.pth\n",
      "train loss 0.5870 val loss 0.6585 and val accuracy 0.6693\n",
      "./models/gru_subset_0.01_loss_658.pth\n",
      "train loss 0.5861 val loss 0.6638 and val accuracy 0.6656\n",
      "train loss 0.5861 val loss 0.6513 and val accuracy 0.6747\n",
      "./models/gru_subset_0.01_loss_651.pth\n",
      "train loss 0.5851 val loss 0.6475 and val accuracy 0.6772\n",
      "./models/gru_subset_0.01_loss_647.pth\n",
      "train loss 0.5845 val loss 0.6486 and val accuracy 0.6765\n",
      "train loss 0.5840 val loss 0.6618 and val accuracy 0.6659\n",
      "train loss 0.5846 val loss 0.6500 and val accuracy 0.6748\n",
      "train loss 0.5828 val loss 0.6467 and val accuracy 0.6773\n",
      "./models/gru_subset_0.01_loss_647.pth\n",
      "train loss 0.5829 val loss 0.6436 and val accuracy 0.6796\n",
      "./models/gru_subset_0.01_loss_644.pth\n",
      "train loss 0.5828 val loss 0.6404 and val accuracy 0.6826\n",
      "./models/gru_subset_0.01_loss_640.pth\n",
      "train loss 0.5822 val loss 0.6471 and val accuracy 0.6768\n",
      "train loss 0.5817 val loss 0.6404 and val accuracy 0.6822\n",
      "./models/gru_subset_0.01_loss_640.pth\n",
      "train loss 0.5813 val loss 0.6464 and val accuracy 0.6774\n",
      "train loss 0.5816 val loss 0.6401 and val accuracy 0.6821\n",
      "./models/gru_subset_0.01_loss_640.pth\n",
      "train loss 0.5810 val loss 0.6447 and val accuracy 0.6786\n",
      "train loss 0.5803 val loss 0.6455 and val accuracy 0.6780\n",
      "train loss 0.5800 val loss 0.6426 and val accuracy 0.6805\n",
      "train loss 0.5794 val loss 0.6509 and val accuracy 0.6740\n",
      "train loss 0.5794 val loss 0.6382 and val accuracy 0.6840\n",
      "./models/gru_subset_0.01_loss_638.pth\n",
      "train loss 0.5786 val loss 0.6413 and val accuracy 0.6802\n",
      "train loss 0.5784 val loss 0.6430 and val accuracy 0.6789\n",
      "train loss 0.5789 val loss 0.6289 and val accuracy 0.6914\n",
      "./models/gru_subset_0.01_loss_629.pth\n",
      "train loss 0.5791 val loss 0.6264 and val accuracy 0.6929\n",
      "./models/gru_subset_0.01_loss_626.pth\n",
      "train loss 0.5782 val loss 0.6424 and val accuracy 0.6801\n",
      "train loss 0.5781 val loss 0.6238 and val accuracy 0.6953\n",
      "./models/gru_subset_0.01_loss_624.pth\n",
      "train loss 0.5786 val loss 0.6301 and val accuracy 0.6890\n",
      "train loss 0.5778 val loss 0.6398 and val accuracy 0.6816\n",
      "train loss 0.5774 val loss 0.6406 and val accuracy 0.6820\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, optimizer, train_dl, valid_dl, max_lr=0.01, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model,'./models/gru_loss_615.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_test(data):\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: max(len(x[0]),len(x[1])), reverse=True) # the max of left and right sentence length\n",
    "    sentences=data\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [max(len(left), len(right)) for left, right in sentences]\n",
    "   \n",
    "    sents_left = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    sents_right = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    \n",
    "    for i, s in enumerate(sentences):\n",
    "        end = len(s[0])\n",
    "        sents_left[i, :end] = torch.Tensor(s[0][:end])        \n",
    "    \n",
    "    for i, s in enumerate(sentences):\n",
    "        end = len(s[1])\n",
    "        sents_right[i, :end] = torch.Tensor(s[1][:end])   \n",
    "    \n",
    "    return sents_left, sents_right, torch.Tensor(lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    '''\n",
    "    Predict keypoints\n",
    "    Args:\n",
    "        data_loader (DataLoader): DataLoader for Dataset\n",
    "        model (nn.Module): trained model for prediction.\n",
    "    Return:\n",
    "        predictions (array-like): keypoints in float (no. of images x keypoints).\n",
    "    '''\n",
    "    \n",
    "    model.eval() # prep model for evaluation\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            output = model(batch[0].long().cuda(),batch[1].long().cuda(),batch[2].long().cuda()).cpu().detach().numpy()\n",
    "            if i == 0:\n",
    "                predictions = output\n",
    "            else:\n",
    "                predictions = np.vstack((predictions, output))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['question1','question2']].applymap(lambda  x: clean_str(str(x))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15257895, 0.30734152, 0.6549154 , 0.71794295, 0.38485667],\n",
       "       [0.10686526, 0.5890985 , 0.65375394, 0.6788295 , 0.21748944],\n",
       "       [0.07896127, 0.09544353, 0.49780664, 0.7442379 , 0.41149992]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_try = QuoraDataset(X_test[:15],np.ones(len(X_test))[:15],False) # train=False\n",
    "test_dl_try = DataLoader(test_ds_try, batch_size=5, collate_fn=collate_fn_test)\n",
    "y_pred_try = predict(test_dl_try,model)\n",
    "y_pred_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = QuoraDataset(X_test,np.ones(len(X_test)),False) # train=False\n",
    "test_dl = DataLoader(test_ds, batch_size=45996, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6313171e-02, 3.2273658e-02, 9.5201237e-03, ..., 5.6876321e-03,\n",
       "        1.0000000e+00, 7.8445245e-03],\n",
       "       [2.1500347e-02, 3.3600889e-02, 7.4507609e-02, ..., 1.7267510e-02,\n",
       "        3.9516229e-02, 8.3519109e-03],\n",
       "       [6.0159652e-03, 1.0827075e-02, 1.5820093e-02, ..., 6.9028310e-02,\n",
       "        5.3718884e-02, 7.0092734e-04],\n",
       "       ...,\n",
       "       [7.8361798e-03, 3.6350276e-02, 2.8158775e-02, ..., 2.0014806e-02,\n",
       "        1.1945239e-02, 3.1880863e-04],\n",
       "       [7.4545760e-03, 3.7449658e-02, 4.3886233e-02, ..., 1.1586647e-02,\n",
       "        2.1522038e-02, 3.9516229e-02],\n",
       "       [3.7218373e-02, 2.4405543e-02, 2.5144551e-02, ..., 1.0000000e+00,\n",
       "        1.0724393e-02, 2.2823377e-02]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(test_dl,model)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.096313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.025636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.014776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.096313\n",
       "1        1      0.032274\n",
       "2        2      0.009520\n",
       "3        3      0.025636\n",
       "4        4      0.014776"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': y_pred.reshape(-1)})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe598a5f190>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(sub.is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43699362874031067"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.is_duplicate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(data_dir/'sample_submission.csv')\n",
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('GRU_MSE_LOGLOSS_615.csv', index=False)\n",
    "# score 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 40.6M/40.6M [00:02<00:00, 19.5MB/s]\n",
      "Successfully submitted to Quora Question Pairs"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c Quora-Question-Pairs -f GRU_MSE_LOGLOSS_615.csv -m \"GRU_MSE_LOGLOSS_615\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
